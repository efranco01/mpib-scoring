{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT:\n",
    "# TODO: Build simple ui or just use terminal for inputs\n",
    "# TODO: Automatically score scripts that have been found in directory\n",
    "\n",
    "# SCORING:\n",
    "# TODO: All proportion correct should be displayed in percentage format\n",
    "# TODO: Make sure to average response time\n",
    "# TODO: Display response times per each response later on\n",
    "# TODO: Response time correct vs incorrect avgs\n",
    "# TODO: Score distance using city block method (will be in the nitty gritty area)\n",
    "# TODO: Score avg distance across trials\n",
    "# TODO: Update to check if more than one of the same test files exist, then score separately\n",
    "\n",
    "# OUTPUT:\n",
    "# TODO: Open csv for each test scored\n",
    "# TODO: Show preliminary information first\n",
    "# TODO: Display more in-depth details further along (horizontal)\n",
    "# TODO: Display avg distance from correct block (incorrect answers) in the \n",
    "# TODO: Place all scored files in scored directory\n",
    "# TODO: Print LOGS stating what is being done\n",
    "\n",
    "# FINAL:\n",
    "# TODO: Migrate .ipynb to .py format and finish syncing script\n",
    "# TODO: Make script executable?!?!\n",
    "# TODO: Allow for more in-depth customization in args (argparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import os\n",
    "import logging as log\n",
    "\n",
    "class Util:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def findFile(self, testName=str):\n",
    "        \n",
    "        # Get the current directory\n",
    "        currentDir = os.getcwd()\n",
    "\n",
    "        # Search for a txt file in the current directory\n",
    "        for file in os.listdir(currentDir):\n",
    "            if file.endswith('.txt'):\n",
    "                if testName in file:\n",
    "                    # If a TXT file is found, read it into a Pandas dataframe\n",
    "                    df = pd.read_csv(os.path.join(currentDir, file), delimiter='\\t')\n",
    "                    print(f'Successfully read file: {file}')\n",
    "                    return df\n",
    "        else:\n",
    "            # If no txt file is found, print an error message\n",
    "            print(f'No TXT file named {testName} found in current directory')\n",
    "\n",
    "    def getTrialType(self, df=pd.DataFrame, trialLoc=4):\n",
    "        \n",
    "        # List different types of trials in the dataframe\n",
    "        trialTypes = df.iloc[:, trialLoc].unique()\n",
    "        \n",
    "        return trialTypes\n",
    "    \n",
    "    def subsetByTrial(self, df=pd.DataFrame, trialTypes=np.ndarray, trialLoc=4):\n",
    "        \n",
    "        # Create a list to hold the subsetted dataframes\n",
    "        subsetList = []\n",
    "        \n",
    "        # Subset data based on trial number\n",
    "        for trial in trialTypes:\n",
    "            # Create a new dataframe for each trial type\n",
    "            trialDf = df[df.iloc[:, trialLoc] == trial]\n",
    "            \n",
    "            # Add each dataframe to a list\n",
    "            subsetList.append(trialDf)\n",
    "        \n",
    "        # Return the list of dataframes\n",
    "        return subsetList\n",
    "    \n",
    "    \n",
    "class InputHandler(Util):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "class OutputHandler(Util):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "myUtil = Util()\n",
    "myOutputHandler = OutputHandler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_FiguralSpeed.txt\n",
      "\n",
      "Scoring PRACT  \n",
      "Proportion correct: 94.87% with total inputs: 39\n",
      "Average response time: 2245.51\n",
      "Average response time for correct answers: 2222.51\n",
      "Average response time for incorrect answers: 2671.00\n",
      "Median response time: 2492.00\n",
      "Median response time for correct answers: 2492.00\n",
      "Median response time for incorrect answers: 2671.00\n",
      "\n",
      "Scoring PRACT  \n",
      "Proportion correct: 95.12% with total inputs: 41\n",
      "Average response time: 2794.46\n",
      "Average response time for correct answers: 2793.79\n",
      "Average response time for incorrect answers: 2807.50\n",
      "Median response time: 2597.00\n",
      "Median response time for correct answers: 2597.00\n",
      "Median response time for incorrect answers: 2807.50\n",
      "\n",
      "Scoring PRACT  \n",
      "Proportion correct: 90.24% with total inputs: 41\n",
      "Average response time: 2523.07\n",
      "Average response time for correct answers: 2518.16\n",
      "Average response time for incorrect answers: 2568.50\n",
      "Median response time: 2444.00\n",
      "Median response time for correct answers: 2444.00\n",
      "Median response time for incorrect answers: 2521.00\n"
     ]
    }
   ],
   "source": [
    "def fsScore():\n",
    "\n",
    "    # grab test document\n",
    "    fs = myUtil.findFile('FiguralSpeed')\n",
    "    \n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(fs)\n",
    "    \n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(fs, trials)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 4]}')\n",
    "        pc = trial.iloc[:, 13].mean()\n",
    "        print(f'Proportion correct: {pc:.2%} with total inputs: {trial.iloc[:, 13].count()}')\n",
    "        responseTimes = trial.iloc[:, 14].mean()\n",
    "        print(f'Average response time: {responseTimes:.2f}')\n",
    "        responseCorrect = trial[trial.iloc[:, 13] == 1].iloc[:, 14].mean()\n",
    "        print(f'Average response time for correct answers: {responseCorrect:.2f}')\n",
    "        responseIncorrect = trial[trial.iloc[:, 13] == 0].iloc[:, 14].mean()\n",
    "        print(f'Average response time for incorrect answers: {responseIncorrect:.2f}')\n",
    "        medianResponseTime = trial.iloc[:, 14].median()\n",
    "        print(f'Median response time: {medianResponseTime:.2f}')\n",
    "        medianResponseCorrect = trial[trial.iloc[:, 13] == 1].iloc[:, 14].median()\n",
    "        print(f'Median response time for correct answers: {medianResponseCorrect:.2f}')\n",
    "        medianResponseIncorrect = trial[trial.iloc[:, 13] == 0].iloc[:, 14].median()\n",
    "        print(f'Median response time for incorrect answers: {medianResponseIncorrect:.2f}')\n",
    "\n",
    "    # score each trial (more specific scores to be outputted later)\n",
    "\n",
    "\n",
    "    # outputs!!!\n",
    "\n",
    "fsScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_LetterUpdating.txt\n",
      "\n",
      "Scoring PRACT  \n",
      "Proportion correct: 66.67% with total inputs: 3\n",
      "\n",
      "Scoring TRIAL1 \n",
      "Proportion correct: 87.50% with total inputs: 8\n",
      "\n",
      "Scoring TRIAL2 \n",
      "Proportion correct: 66.67% with total inputs: 8\n"
     ]
    }
   ],
   "source": [
    "# TODO: The PRACT subset only has 3 instead of 4 inputs!\n",
    "\n",
    "def luScore():\n",
    "    \n",
    "    #  grab test document\n",
    "    lu = myUtil.findFile('LetterUpdating')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(lu)\n",
    "\n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(lu, trials)\n",
    "    \n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 4]}')\n",
    "        pc = trial.iloc[:, 18].mean() / 3\n",
    "        print(f'Proportion correct: {pc:.2%} with total inputs: {trial.iloc[:, 18].count()}')\n",
    "\n",
    "    # outputs!!!\n",
    "\n",
    "luScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_MotoricSpeed.txt\n",
      "\n",
      "Scoring PRACT1\n",
      "Proportion correct: 59.09% with total inputs: 22\n",
      "Average response time: 269.23\n",
      "Average response time for correct answers: 423.69\n",
      "Average response time for incorrect answers: 46.11\n",
      "Median response time: 307.50\n",
      "Median response time for correct answers: 354.00\n",
      "Median response time for incorrect answers: 0.00\n",
      "\n",
      "Scoring 5\n",
      "Proportion correct: nan% with total inputs: 0\n",
      "Average response time: nan\n",
      "Average response time for correct answers: nan\n",
      "Average response time for incorrect answers: nan\n",
      "Median response time: nan\n",
      "Median response time for correct answers: nan\n",
      "Median response time for incorrect answers: nan\n",
      "\n",
      "Scoring PRACT2\n",
      "Proportion correct: 100.00% with total inputs: 24\n",
      "Average response time: 318.88\n",
      "Average response time for correct answers: 318.88\n",
      "Average response time for incorrect answers: nan\n",
      "Median response time: 303.00\n",
      "Median response time for correct answers: 303.00\n",
      "Median response time for incorrect answers: nan\n",
      "\n",
      "Scoring TRIAL1\n",
      "Proportion correct: 95.83% with total inputs: 48\n",
      "Average response time: 294.96\n",
      "Average response time for correct answers: 297.48\n",
      "Average response time for incorrect answers: 237.00\n",
      "Median response time: 281.00\n",
      "Median response time for correct answers: 285.50\n",
      "Median response time for incorrect answers: 237.00\n",
      "\n",
      "Scoring TRIAL2\n",
      "Proportion correct: 100.00% with total inputs: 48\n",
      "Average response time: 321.77\n",
      "Average response time for correct answers: 321.77\n",
      "Average response time for incorrect answers: nan\n",
      "Median response time: 311.50\n",
      "Median response time for correct answers: 311.50\n",
      "Median response time for incorrect answers: nan\n",
      "\n",
      "Scoring TRIAL3\n",
      "Proportion correct: 95.83% with total inputs: 48\n",
      "Average response time: 380.62\n",
      "Average response time for correct answers: 393.61\n",
      "Average response time for incorrect answers: 82.00\n",
      "Median response time: 371.50\n",
      "Median response time for correct answers: 372.50\n",
      "Median response time for incorrect answers: 82.00\n",
      "\n",
      "Scoring TRIAL4\n",
      "Proportion correct: 100.00% with total inputs: 48\n",
      "Average response time: 367.44\n",
      "Average response time for correct answers: 367.44\n",
      "Average response time for incorrect answers: nan\n",
      "Median response time: 331.00\n",
      "Median response time for correct answers: 331.00\n",
      "Median response time for incorrect answers: nan\n",
      "\n",
      "Scoring TRIAL5\n",
      "Proportion correct: 97.92% with total inputs: 48\n",
      "Average response time: 321.44\n",
      "Average response time for correct answers: 321.85\n",
      "Average response time for incorrect answers: 302.00\n",
      "Median response time: 312.50\n",
      "Median response time for correct answers: 314.00\n",
      "Median response time for incorrect answers: 302.00\n",
      "\n",
      "Scoring TRIAL6\n",
      "Proportion correct: 95.83% with total inputs: 48\n",
      "Average response time: 304.77\n",
      "Average response time for correct answers: 305.76\n",
      "Average response time for incorrect answers: 282.00\n",
      "Median response time: 302.00\n",
      "Median response time for correct answers: 303.00\n",
      "Median response time for incorrect answers: 282.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "def msScore():\n",
    "    \n",
    "    # grab test document\n",
    "    ms = myUtil.findFile('MotoricSpeed')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(ms, 5)\n",
    "\n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(ms, trials, 5)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 5]}')\n",
    "        pc = trial.iloc[:, 15].mean()\n",
    "        print(f'Proportion correct: {pc:.2%} with total inputs: {trial.iloc[:, 13].count()}')\n",
    "        responseTimes = trial.iloc[:, 14].mean()\n",
    "        print(f'Average response time: {responseTimes:.2f}')\n",
    "        responseCorrect = trial[trial.iloc[:, 15] == 1].iloc[:, 14].mean()\n",
    "        print(f'Average response time for correct answers: {responseCorrect:.2f}')\n",
    "        responseIncorrect = trial[trial.iloc[:, 15] == 0].iloc[:, 14].mean()\n",
    "        print(f'Average response time for incorrect answers: {responseIncorrect:.2f}')\n",
    "        medianResponseTime = trial.iloc[:, 14].median()\n",
    "        print(f'Median response time: {medianResponseTime:.2f}')\n",
    "        medianResponseCorrect = trial[trial.iloc[:, 15] == 1].iloc[:, 14].median()\n",
    "        print(f'Median response time for correct answers: {medianResponseCorrect:.2f}')\n",
    "        medianResponseIncorrect = trial[trial.iloc[:, 15] == 0].iloc[:, 14].median()\n",
    "        print(f'Median response time for incorrect answers: {medianResponseIncorrect:.2f}')\n",
    "\n",
    "msScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_NumberMemory.txt\n",
      "\n",
      "Scoring PRACT1 \n",
      "Proportion correct: 22.22% with total inputs: 9\n",
      "Average response time: 4411.22\n",
      "Average response time for correct answers: 3969.50\n",
      "Average response time for incorrect answers: 4537.43\n",
      "Median response time: 3594.00\n",
      "Median response time for correct answers: 3969.50\n",
      "Median response time for incorrect answers: 3252.00\n",
      "\n",
      "Scoring TRIAL1 \n",
      "Proportion correct: 20.00% with total inputs: 10\n",
      "Average response time: 3808.90\n",
      "Average response time for correct answers: 1567.00\n",
      "Average response time for incorrect answers: 4369.38\n",
      "Median response time: 3932.00\n",
      "Median response time for correct answers: 1567.00\n",
      "Median response time for incorrect answers: 4055.00\n",
      "\n",
      "Scoring TRIAL2 \n",
      "Proportion correct: 30.00% with total inputs: 10\n",
      "Average response time: 2808.70\n",
      "Average response time for correct answers: 2510.67\n",
      "Average response time for incorrect answers: 2936.43\n",
      "Median response time: 3013.00\n",
      "Median response time for correct answers: 1788.00\n",
      "Median response time for incorrect answers: 3184.00\n"
     ]
    }
   ],
   "source": [
    "def nmScore():\n",
    "    \n",
    "    # grab test document\n",
    "    nm = myUtil.findFile('NumberMemory')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(nm, 4)\n",
    "\n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(nm, trials)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 4]}')\n",
    "        pc = trial.iloc[:, 10].mean()\n",
    "        print(f'Proportion correct: {pc:.2%} with total inputs: {trial.iloc[:, 13].count()}')\n",
    "        responseTimes = trial.iloc[:, 11].mean()\n",
    "        print(f'Average response time: {responseTimes:.2f}')\n",
    "        responseCorrect = trial[trial.iloc[:, 10] == 1].iloc[:, 11].mean()\n",
    "        print(f'Average response time for correct answers: {responseCorrect:.2f}')\n",
    "        responseIncorrect = trial[trial.iloc[:, 10] == 0].iloc[:, 11].mean()\n",
    "        print(f'Average response time for incorrect answers: {responseIncorrect:.2f}')\n",
    "        medianResponseTime = trial.iloc[:, 11].median()\n",
    "        print(f'Median response time: {medianResponseTime:.2f}')\n",
    "        medianResponseCorrect = trial[trial.iloc[:, 10] == 1].iloc[:, 11].median()\n",
    "        print(f'Median response time for correct answers: {medianResponseCorrect:.2f}')\n",
    "        medianResponseIncorrect = trial[trial.iloc[:, 10] == 0].iloc[:, 11].median()\n",
    "        print(f'Median response time for incorrect answers: {medianResponseIncorrect:.2f}')\n",
    "\n",
    "nmScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_Numerical_nBack.txt\n",
      "['PRACT_1  ' 'PRACT_2  ' 'TRIAL1_1 ' 'TRIAL1_2 ' 'TRIAL2_1 ' 'TRIAL2_2 ']\n",
      "\n",
      "Scoring PRACT_1  \n",
      "Proportion correct: 58.62% (total correct = 17) with total inputs: 29\n",
      "Average response time: 484.14\n",
      "Average response time for correct answers: 825.88\n",
      "Average response time for incorrect answers: 0.00\n",
      "Median response time: 700.00\n",
      "Median response time for correct answers: 785.00\n",
      "Median response time for incorrect answers: 0.00\n",
      "\n",
      "Scoring PRACT_2  \n",
      "Proportion correct: 86.67% (total correct = 26) with total inputs: 30\n",
      "Average response time: 672.67\n",
      "Average response time for correct answers: 729.31\n",
      "Average response time for incorrect answers: 304.50\n",
      "Median response time: 679.00\n",
      "Median response time for correct answers: 699.50\n",
      "Median response time for incorrect answers: 0.00\n",
      "\n",
      "Scoring TRIAL1_1 \n",
      "Proportion correct: 86.67% (total correct = 26) with total inputs: 30\n",
      "Average response time: 649.17\n",
      "Average response time for correct answers: 749.04\n",
      "Average response time for incorrect answers: 0.00\n",
      "Median response time: 677.50\n",
      "Median response time for correct answers: 695.50\n",
      "Median response time for incorrect answers: 0.00\n",
      "\n",
      "Scoring TRIAL1_2 \n",
      "Proportion correct: 90.00% (total correct = 27) with total inputs: 30\n",
      "Average response time: 605.60\n",
      "Average response time for correct answers: 672.89\n",
      "Average response time for incorrect answers: 0.00\n",
      "Median response time: 620.50\n",
      "Median response time for correct answers: 646.00\n",
      "Median response time for incorrect answers: 0.00\n",
      "\n",
      "Scoring TRIAL2_1 \n",
      "Proportion correct: 90.00% (total correct = 27) with total inputs: 30\n",
      "Average response time: 624.67\n",
      "Average response time for correct answers: 694.07\n",
      "Average response time for incorrect answers: 0.00\n",
      "Median response time: 639.50\n",
      "Median response time for correct answers: 661.00\n",
      "Median response time for incorrect answers: 0.00\n",
      "\n",
      "Scoring TRIAL2_2 \n",
      "Proportion correct: 73.33% (total correct = 22) with total inputs: 30\n",
      "Average response time: 644.07\n",
      "Average response time for correct answers: 716.00\n",
      "Average response time for incorrect answers: 446.25\n",
      "Median response time: 658.00\n",
      "Median response time for correct answers: 675.50\n",
      "Median response time for incorrect answers: 248.00\n"
     ]
    }
   ],
   "source": [
    "# this test has a different trial format and the column is 6 instead of 5\n",
    "def nbScore():\n",
    "    \n",
    "    # grab test document\n",
    "    nb = myUtil.findFile('Numerical_nBack')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(nb, 5)\n",
    "    print(trials)\n",
    "\n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(nb, trials, 5)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 5]}')\n",
    "        pc = trial.iloc[:, 13].mean()\n",
    "        totalCorrect = trial.iloc[:, 13].sum()\n",
    "        print(f'Proportion correct: {pc:.2%} (total correct = {totalCorrect}) with total inputs: {trial.iloc[:, 13].count()}')\n",
    "        responseTimes = trial.iloc[:, 14].mean()\n",
    "        print(f'Average response time: {responseTimes:.2f}')\n",
    "        responseCorrect = trial[trial.iloc[:, 13] == 1].iloc[:, 14].mean()\n",
    "        print(f'Average response time for correct answers: {responseCorrect:.2f}')\n",
    "        responseIncorrect = trial[trial.iloc[:, 13] == 0].iloc[:, 14].mean()\n",
    "        print(f'Average response time for incorrect answers: {responseIncorrect:.2f}')\n",
    "        medianResponseTime = trial.iloc[:, 14].median()\n",
    "        print(f'Median response time: {medianResponseTime:.2f}')\n",
    "        medianResponseCorrect = trial[trial.iloc[:, 13] == 1].iloc[:, 14].median()\n",
    "        print(f'Median response time for correct answers: {medianResponseCorrect:.2f}')\n",
    "        medianResponseIncorrect = trial[trial.iloc[:, 13] == 0].iloc[:, 14].median()\n",
    "        print(f'Median response time for incorrect answers: {medianResponseIncorrect:.2f}')\n",
    "\n",
    "nbScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_NumericalSpeed.txt\n",
      "\n",
      "Scoring PRACT\n",
      "Proportion correct: 94.87% with total inputs: 39\n",
      "Average response time: 1036.67\n",
      "Average response time for correct answers: 1021.03\n",
      "Average response time for incorrect answers: 1326.00\n",
      "Median response time: 993.00\n",
      "Median response time for correct answers: 978.00\n",
      "Median response time for incorrect answers: 1326.00\n",
      "\n",
      "Scoring TRIAL1\n",
      "Proportion correct: 95.00% with total inputs: 40\n",
      "Average response time: 1050.78\n",
      "Average response time for correct answers: 1062.18\n",
      "Average response time for incorrect answers: 834.00\n",
      "Median response time: 1014.00\n",
      "Median response time for correct answers: 1026.00\n",
      "Median response time for incorrect answers: 834.00\n",
      "\n",
      "Scoring TRIAL2\n",
      "Proportion correct: 100.00% with total inputs: 40\n",
      "Average response time: 1031.97\n",
      "Average response time for correct answers: 1031.97\n",
      "Average response time for incorrect answers: nan\n",
      "Median response time: 978.00\n",
      "Median response time for correct answers: 978.00\n",
      "Median response time for incorrect answers: nan\n"
     ]
    }
   ],
   "source": [
    "def nsScore():\n",
    "    \n",
    "    # grab test document\n",
    "    ns = myUtil.findFile('NumericalSpeed')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(ns, 4)\n",
    "\n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(ns, trials)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 4]}')\n",
    "        pc = trial.iloc[:, 13].mean()\n",
    "        print(f'Proportion correct: {pc:.2%} with total inputs: {trial.iloc[:, 13].count()}')\n",
    "        responseTimes = trial.iloc[:, 14].mean()\n",
    "        print(f'Average response time: {responseTimes:.2f}')\n",
    "        responseCorrect = trial[trial.iloc[:, 13] == 1].iloc[:, 14].mean()\n",
    "        print(f'Average response time for correct answers: {responseCorrect:.2f}')\n",
    "        responseIncorrect = trial[trial.iloc[:, 13] == 0].iloc[:, 14].mean()\n",
    "        print(f'Average response time for incorrect answers: {responseIncorrect:.2f}')\n",
    "        medianResponseTime = trial.iloc[:, 14].median()\n",
    "        print(f'Median response time: {medianResponseTime:.2f}')\n",
    "        medianResponseCorrect = trial[trial.iloc[:, 13] == 1].iloc[:, 14].median()\n",
    "        print(f'Median response time for correct answers: {medianResponseCorrect:.2f}')\n",
    "        medianResponseIncorrect = trial[trial.iloc[:, 13] == 0].iloc[:, 14].median()\n",
    "        print(f'Median response time for incorrect answers: {medianResponseIncorrect:.2f}')\n",
    "\n",
    "nsScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_SpeedTabbing.txt\n",
      "\n",
      "Scoring PRACT1\n",
      "Total number of presses: 158\n",
      "Average response time: 123.00\n",
      "Median response time: 120.00\n",
      "First press (ms): 120.00 and last press (ms): 128.00\n",
      "\n",
      "Scoring PRACT2\n",
      "Total number of presses: 130\n",
      "Average response time: 152.59\n",
      "Median response time: 151.00\n",
      "First press (ms): 253.00 and last press (ms): 127.00\n",
      "\n",
      "Scoring TRIAL1\n",
      "Total number of presses: 156\n",
      "Average response time: 127.56\n",
      "Median response time: 127.00\n",
      "First press (ms): 77.00 and last press (ms): 119.00\n",
      "\n",
      "Scoring TRIAL2\n",
      "Total number of presses: 136\n",
      "Average response time: 146.21\n",
      "Median response time: 136.00\n",
      "First press (ms): 87.00 and last press (ms): 167.00\n"
     ]
    }
   ],
   "source": [
    "def stScore():\n",
    "    \n",
    "    # grab test document\n",
    "    st = myUtil.findFile('SpeedTabbing')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(st)\n",
    "\n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(st, trials)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 4]}')\n",
    "        numPresses = trial.iloc[:, 5].count()\n",
    "        print(f'Total number of presses: {numPresses}')\n",
    "        responseTimes = trial.iloc[:, 10].mean()\n",
    "        print(f'Average response time: {responseTimes:.2f}')\n",
    "        medianResponseTime = trial.iloc[:, 10].median()\n",
    "        print(f'Median response time: {medianResponseTime:.2f}')\n",
    "        firstPress = trial.iloc[0, 10]\n",
    "        lastPress = trial.iloc[-1, 10]\n",
    "        print(f'First press (ms): {firstPress:.2f} and last press (ms): {lastPress:.2f}')\n",
    "        \n",
    "stScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_VerbalSpeed.txt\n",
      "\n",
      "Scoring PRACT\n",
      "Proportion correct: 100.00% with total inputs: 39\n",
      "Average response time: 1053.38\n",
      "Average response time for correct answers: 1053.38\n",
      "Average response time for incorrect answers: nan\n",
      "Median response time: 1026.00\n",
      "Median response time for correct answers: 1026.00\n",
      "Median response time for incorrect answers: nan\n",
      "\n",
      "Scoring TRIAL1\n",
      "Proportion correct: 97.50% with total inputs: 40\n",
      "Average response time: 1035.05\n",
      "Average response time for correct answers: 1038.38\n",
      "Average response time for incorrect answers: 905.00\n",
      "Median response time: 1014.50\n",
      "Median response time for correct answers: 1034.00\n",
      "Median response time for incorrect answers: 905.00\n",
      "\n",
      "Scoring TRIAL2\n",
      "Proportion correct: 100.00% with total inputs: 40\n",
      "Average response time: 950.80\n",
      "Average response time for correct answers: 950.80\n",
      "Average response time for incorrect answers: nan\n",
      "Median response time: 910.00\n",
      "Median response time for correct answers: 910.00\n",
      "Median response time for incorrect answers: nan\n"
     ]
    }
   ],
   "source": [
    "def vsScore():\n",
    "    \n",
    "    # grab test document\n",
    "    vs = myUtil.findFile('VerbalSpeed')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(vs)\n",
    "\n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(vs, trials)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 4]}')\n",
    "        pc = trial.iloc[:, 13].mean()\n",
    "        print(f'Proportion correct: {pc:.2%} with total inputs: {trial.iloc[:, 13].count()}')\n",
    "        responseTimes = trial.iloc[:, 14].mean()\n",
    "        print(f'Average response time: {responseTimes:.2f}')\n",
    "        responseCorrect = trial[trial.iloc[:, 13] == 1].iloc[:, 14].mean()\n",
    "        print(f'Average response time for correct answers: {responseCorrect:.2f}')\n",
    "        responseIncorrect = trial[trial.iloc[:, 13] == 0].iloc[:, 14].mean()\n",
    "        print(f'Average response time for incorrect answers: {responseIncorrect:.2f}')\n",
    "        medianResponseTime = trial.iloc[:, 14].median()\n",
    "        print(f'Median response time: {medianResponseTime:.2f}')\n",
    "        medianResponseCorrect = trial[trial.iloc[:, 13] == 1].iloc[:, 14].median()\n",
    "        print(f'Median response time for correct answers: {medianResponseCorrect:.2f}')\n",
    "        medianResponseIncorrect = trial[trial.iloc[:, 13] == 0].iloc[:, 14].median()\n",
    "        print(f'Median response time for incorrect answers: {medianResponseIncorrect:.2f}')\n",
    "        \n",
    "vsScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_ObjectLocationMemory.txt\n",
      "['TRIAL1' 'TRIAL2']\n",
      "\n",
      "Scoring TRIAL1\n",
      "Proportion correct: 7 of 12\n",
      "Total response time: 159040.00 ms\n",
      "\n",
      "Scoring TRIAL2\n",
      "Proportion correct: 6 of 12\n",
      "Total response time: 148840.00 ms\n"
     ]
    }
   ],
   "source": [
    "def olmScore():\n",
    "\n",
    "    # NOTE: consists of 6x6 grid of objects\n",
    "    \n",
    "    # grab test document\n",
    "    olm = myUtil.findFile('ObjectLocationMemory')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(olm)\n",
    "    print(trials)\n",
    "    \n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(olm, trials)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 4]}')\n",
    "        pc = trial.iloc[:, 9].item()\n",
    "        print(f'Proportion correct: {pc} of 12')\n",
    "        responseTimes = trial.iloc[:, 7].item()\n",
    "        print(f'Total response time: {responseTimes:.2f} ms')\n",
    "\n",
    "    # Nitty gritty details\n",
    "    # 1. Determine the original coordinates of the object\n",
    "    # 2. Determine the coordinates of the object after the translation\n",
    "\n",
    "olmScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_SpatialUpdating.txt\n",
      "['PRACT' 'TRIAL1' 'TRIAL2']\n",
      "\n",
      "Scoring PRACT\n",
      "Proportion correct for grid 1: 100.00% with total inputs: 4\n",
      "Proportion correct for grid 2: 25.00% with total inputs: 4\n",
      "Proportion correct for grid 3: 50.00% with total inputs: 4\n",
      "Proportion correct for all grids correct: 0.00% with total inputs: 4\n",
      "\n",
      "Scoring TRIAL1\n",
      "Proportion correct for grid 1: 80.00% with total inputs: 5\n",
      "Proportion correct for grid 2: 40.00% with total inputs: 5\n",
      "Proportion correct for grid 3: 20.00% with total inputs: 5\n",
      "Proportion correct for all grids correct: 20.00% with total inputs: 5\n",
      "\n",
      "Scoring TRIAL2\n",
      "Proportion correct for grid 1: 40.00% with total inputs: 5\n",
      "Proportion correct for grid 2: 40.00% with total inputs: 5\n",
      "Proportion correct for grid 3: 40.00% with total inputs: 5\n",
      "Proportion correct for all grids correct: 0.00% with total inputs: 5\n"
     ]
    }
   ],
   "source": [
    "def suScore():\n",
    "    # NOTE: consists of 3, 3x3 grids of objects\n",
    "    \n",
    "    # grab test document\n",
    "    su = myUtil.findFile('SpatialUpdating')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(su)\n",
    "    print(trials)\n",
    "\n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(su, trials)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 4]}')\n",
    "        pcGrid1 = trial.iloc[:, 33].mean()\n",
    "        pcGrid2 = trial.iloc[:, 34].mean()\n",
    "        pcGrid3 = trial.iloc[:, 35].mean()\n",
    "        pcTotal = trial.iloc[:, 36].mean()\n",
    "        print(f'Proportion correct for grid 1: {pcGrid1:.2%} with total inputs: {trial.iloc[:, 33].count()}')\n",
    "        print(f'Proportion correct for grid 2: {pcGrid2:.2%} with total inputs: {trial.iloc[:, 34].count()}')\n",
    "        print(f'Proportion correct for grid 3: {pcGrid3:.2%} with total inputs: {trial.iloc[:, 35].count()}')\n",
    "        print(f'Proportion correct for all grids correct: {pcTotal:.2%} with total inputs: {trial.iloc[:, 36].count()}')\n",
    "        \n",
    "\n",
    "    # Nitty gritty details\n",
    "    # 1. Determine the original coordinates of the object\n",
    "    # 2. Determine the coordinates of the object after the translation\n",
    "    \n",
    "suScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read file: 1001_WordRecall.txt\n",
      "\n",
      "Scoring TRIAL1\n",
      "Proportion correct: 100.00% with total responses: 11\n",
      "Proportion of intrusions: 0.00% with total responses: 11\n",
      "\n",
      "Scoring TRIAL2\n",
      "Proportion correct: 88.89% with total responses: 9\n",
      "Proportion of intrusions: 11.11% with total responses: 9\n"
     ]
    }
   ],
   "source": [
    "def wrScore():\n",
    "    \n",
    "    # grab test document\n",
    "    wr = myUtil.findFile('WordRecall')\n",
    "\n",
    "    # determine all unique trials\n",
    "    trials = myUtil.getTrialType(wr)\n",
    "\n",
    "    # subset data by trial\n",
    "    trialDfs = myUtil.subsetByTrial(wr, trials)\n",
    "\n",
    "    # score each trial (this will be general scores)\n",
    "    for trial in trialDfs:\n",
    "        print(f'\\nScoring {trial.iloc[0, 4]}')\n",
    "        pc = trial.iloc[:, 24].item() / trial.iloc[:, 23].item()\n",
    "        print(f'Proportion correct: {pc:.2%} with total responses: {trial.iloc[:, 23].item()}')\n",
    "        intrusions = trial.iloc[:, 25].item() / trial.iloc[:, 23].item()\n",
    "        print(f'Proportion of intrusions: {intrusions:.2%} with total responses: {trial.iloc[:, 23].item()}')\n",
    "        \n",
    "\n",
    "wrScore()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
